{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b391bde",
   "metadata": {},
   "source": [
    "# Creating an intelligent and advanced RAG for movie recommendation\n",
    "**A continuation to the previous project: [here](https://github.com/SajalPaudyal/Implementing_basic_RAG_for_movie_recommendation/blob/main/Information_Retrieval/a_movie_reccomender.ipynb)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a783c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sajalpaudyal/Documents/Programming_Works/advanced_rag/lib64/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import faiss\n",
    "import torch\n",
    "import chromadb\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "from langchain_groq import ChatGroq\n",
    "from elasticsearch import Elasticsearch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BertTokenizer, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf913f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "elastic_api = os.getenv(\"ELASTIC_API_KEY\")\n",
    "elastic_cloud_id = os.getenv(\"ELASTIC_CLOUD_ID\")\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "login = login(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5db489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_transformer = SentenceTransformer(\"all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1171c402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm():\n",
    "    model = ChatGroq(\n",
    "        model=\"qwen/qwen3-32b\",\n",
    "        temperature = 1.0,\n",
    "        max_tokens=1024,\n",
    "        timeout=None,\n",
    "        max_retries=2\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf5e5cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1cb2e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "es = Elasticsearch(cloud_id=elastic_cloud_id, api_key=elastic_api)\n",
    "es.ping()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a43c39b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'movies' already exists.\n"
     ]
    }
   ],
   "source": [
    "index_body = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"content\": {\"type\": \"text\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = 'movies'\n",
    "if not es.indices.exists(index=index_name):\n",
    "    es.indices.create(index=index_name, body=index_body)\n",
    "    print(f\"Index '{index_name}' created.\")\n",
    "else:\n",
    "    print(f\"Index '{index_name}' already exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a8cb7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "rerank_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "rerank_model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5620d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "if \"GROQ_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f392300",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_groq_model = get_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8143a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_query_transformation(query):\n",
    "    expanded_query = query + \" OR related_term\"\n",
    "    return expanded_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0045fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_query_routing(query):\n",
    "    if \"specific_keyword\" in query:\n",
    "        return \"textual\"\n",
    "    else:\n",
    "        return \"vector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdda3cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusion Retrieval Function\n",
    "def fusion_retrieval(query, top_k=5):\n",
    "    \n",
    "    query_embedding = sentence_transformer.encode(query).tolist()\n",
    "    vector_results = collection.query(query_embeddings=[query_embedding], n_results=min(top_k, len(documents)))\n",
    "\n",
    "    # Textual retrieval using Elasticsearch\n",
    "    es_body = {\n",
    "        \"size\": top_k,  # Move size into body\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"content\": query\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    es_results = es.search(index=index_name, body=es_body)\n",
    "    es_documents = [hit[\"_source\"][\"content\"] for hit in es_results['hits']['hits']]\n",
    "    \n",
    "    combined_results = vector_results['documents'][0] + es_documents\n",
    "\n",
    "    return combined_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9347bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def rerank_documents(query, documents):\n",
    "    \"\"\"\n",
    "    Reranks the retrieved documents based on their relevance to the query using a pre-trained\n",
    "    BERT model.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user's query.\n",
    "        documents (list): A list of documents retrieved from the search.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of reranked documents, sorted by relevance.\n",
    "    \"\"\"\n",
    "    inputs = [rerank_tokenizer.encode_plus(query, doc, return_tensors='pt', truncation=True, padding=True) for doc in documents]\n",
    "\n",
    "    scores = []\n",
    "    for input in inputs:\n",
    "        outputs = rerank_model(**input)\n",
    "        logits = outputs.logits\n",
    "        probabilities = F.softmax(logits, dim=1)\n",
    "        positive_class_probability = probabilities[:, 1].item()  # Assuming the second element represents the positive class\n",
    "        scores.append(positive_class_probability)\n",
    "\n",
    "    ranked_docs = sorted(zip(documents, scores), key=lambda x: x[1], reverse=True)\n",
    "    return [doc for doc, score in ranked_docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9df8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bca9cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_and_compress_context(documents):\n",
    "    \"\"\"\n",
    "    Summarizes the content of the retrieved documents to create a compressed context.\n",
    "\n",
    "    Args:\n",
    "        documents (list): A list of documents to summarize.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of summarized texts for each document.\n",
    "    \"\"\"\n",
    "    summarized_context = []\n",
    "    for doc in documents:\n",
    "        input_length = len(doc.split())  # Calculate input length based on word count\n",
    "        max_length = min(100, input_length)  # Set max_length to input_length if smaller than 100\n",
    "        summary = summarizer(doc, max_length=max_length, min_length=5, do_sample=False)[0]['summary_text']\n",
    "        summarized_context.append(summary)\n",
    "    return summarized_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204ffab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer Generation Function\n",
    "def generate_answer(query, chunks, llm):\n",
    "    \"\"\"\n",
    "    Generates an answer based on the input query and context chunks using a language model.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user's query.\n",
    "        chunks (list): A list of context chunks to inform the answer.\n",
    "        llm (ChatGroq): An instance of the ChatGroq language model.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated answer.\n",
    "    \"\"\"\n",
    "    context = \"\\n\\n\".join(chunks)\n",
    "\n",
    "    prompt = f\"\"\"[INST]\n",
    "Instruction: You're an expert in movie suggestions. Your task is to analyze carefully the context and come up with an exhaustive answer to the following question:\n",
    "{query}\n",
    "\n",
    "Here is the context to help you:\n",
    "\n",
    "{context}\n",
    "\n",
    "[/INST]\"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)  \n",
    "\n",
    "    generated_text = response.content\n",
    "\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46124a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_rag_pipeline(query):\n",
    "    \"\"\"\n",
    "    The main pipeline function for the Advanced Retrieval-Augmented Generation (RAG) system.\n",
    "    It processes the query, retrieves relevant documents, reranks them, selects and compresses\n",
    "    the context, and finally generates an answer.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user's input query.\n",
    "\n",
    "    Returns:\n",
    "        str: The final generated answer.\n",
    "    \"\"\"\n",
    "    transformed_query = advanced_query_transformation(query)\n",
    "    retrieval_method = advanced_query_routing(transformed_query)\n",
    "\n",
    "    retrieved_documents = fusion_retrieval(transformed_query)\n",
    "\n",
    "    ranked_documents = rerank_documents(query, retrieved_documents)\n",
    "\n",
    "    context = select_and_compress_context(ranked_documents)\n",
    "\n",
    "    final_answer = generate_answer(query, context, get_groq_model)\n",
    "    return final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbcc9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'movies' created successfully.\n",
      "Documents inserted successfully.\n"
     ]
    }
   ],
   "source": [
    "client = chromadb.Client()\n",
    "\n",
    "collection_name = \"movies\"\n",
    "\n",
    "try:\n",
    "    collection = client.create_collection(name=collection_name)\n",
    "    print(f\"Collection '{collection_name}' created successfully.\")\n",
    "\n",
    "    documents = [\n",
    "        {\"id\": \"1\", \"content\": \"The Shawshank Redemption is a great movie to watch on a rainy day.\"},\n",
    "        {\"id\": \"2\", \"content\": \"Forrest Gump is an uplifting film perfect for a rainy afternoon.\"}\n",
    "    ]\n",
    "\n",
    "    ids = [doc[\"id\"] for doc in documents]\n",
    "    contents = [doc[\"content\"] for doc in documents]\n",
    "\n",
    "    collection.add(ids=ids, documents=contents)\n",
    "    print(\"Documents inserted successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Collection '{collection_name}' already exists. No need to create it again.\")\n",
    "    collection = client.get_collection(name=collection_name)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2689dbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, I need to come up with a list of good movies to watch on a rainy day based on the context provided. The context mentions \"Forrest Gump is an uplifting film\" and \"The Shawshank Redemption is a great movie to...\" but it's cut off. Let me start by thinking about what makes a movie good for rainy days.\n",
      "\n",
      "Rainy days often make people want to stay inside, so maybe comfort movies that are feel-good, nostalgic, or have a warm atmosphere. The context mentions uplifting films and The Shawshank Redemption, which is a classic. Shawshank is more of a prison drama with hope, but it's a popular choice. So maybe include uplifting movies with emotional depth.\n",
      "\n",
      "Forrest Gump is a good example, so other uplifting dramas might work. Also, maybe classics, comedies for a lighter mood, or dramas that evoke reflection. I should consider different genres but focus on films that are cozy or have a satisfying story that keeps you engaged all day.\n",
      "\n",
      "The user might want a mix of genres for variety. Let me think of some movies. The Shawshank Redemption is definitely a top recommendation. Then maybe The Green Mile, which is another Stephen King adaptation, but that's more darker. Wait, the user might prefer uplifting. Let me check Forest Gump's genre; it's a drama but with a hopeful outlook.\n",
      "\n",
      "Maybe include other feel-good movies like \"Good Will Hunting,\" which is a drama with emotional depth. \"The Straight Story\" by David Lynch could be a calm, meditative option. For comedy, maybe \"Legally Blonde\" for lightheartedness. \n",
      "\n",
      "Also, consider some animated films if the user wants to mix things up, like \"Spirited Away\" for a different vibe. Documentaries aren't mentioned in the context but might be safe to include if they fit the theme, like \"Chef's Table\" for a cozy mood.\n",
      "\n",
      "Wait, the context didn't mention any other films except the two given. The user might want to stick to similar categories. Let me think of other uplifting dramas: maybe \"The Pursuit of Happyness,\" \"Rocky,\" \"A Beautiful Mind.\" Classics like \"Casablanca\" or \"Gone with the Wind\" might also be good for a rainy day.\n",
      "\n",
      "Also, some romantic comedies: \"When Harry Met Sally,\" \"You've Got Mail.\" Or family-friendly movies like \"The Sandlot.\" For something a little different, maybe \"Eternal Sunshine of the Spotless Mind\" for a moody, introspective mood. \n",
      "\n",
      "I need to ensure the list isn't just action movies. The Shawshank Redemption is a classic, so maybe include more of the IMDb \"Top 250\" movies. Let me list a few from there: \"The Godfather,\" \"Citizen Kane\" if the user is in the mood for serious drama, \"Chinatown,\" but those are more intense. Perhaps focus on the ones that are feel-good or have a nostalgic feel.\n",
      "\n",
      "Wait, the user is looking for a rainy day, so maybe more emotional resonance. Also, think about movies that can be watched in an afternoon, so not too long. Or maybe long films are okay if they're engaging. For example, \"Titanic\" is a long movie but emotionally compelling. \n",
      "\n",
      "Including a variety of genres would cover different tastes. So the list should have a mix of drama, comedy, romance, and maybe some classics. Let me compile the list now, making sure each movie fits the theme of being suitable for a rainy day. I need to check for any movies that might be too intense or inappropriate. For example, \"Schindler's List\" is too serious for a relaxed day. \n",
      "\n",
      "So finalizing the list: The Shawshank Redemption, Forrest Gump, The Pursuit of Happyness, The Straight Story, Legally Blonde, Titanic, Casablanca, When Harry Met Sally, A Beautiful Mind, Good Will Hunting, Eternal Sunshine of the Spotless Mind, Spirited Away, Chef's Table (documentary), The Godfather, The Green Mile, A Dog's Purpose, The Secret Life of Walter Mitty, 127 Hours, The Theory of Everything, Good Day Saigon, etc.\n",
      "\n",
      "Wait, some of these might be too varied. The user might want movies that match the given context's tone. The given examples are \"Forrest Gump\" and \"The Shawshank Redemption,\" so maybe stick to uplifting or emotionally resonant dramas and some comedies. Let me adjust the list to include more of those. Also, check the categories again. I'll provide a concise yet diverse list with explanations for each to justify why they're good for rainy days.\n",
      "</think>\n",
      "\n",
      "Hereâ€™s an exhaustive list of movies perfect for a rainy day, categorized to match moods and tones from the context you provided (\"*Forrest Gump is an uplifting film*\" and \"*The Shawshank Redemption is a great movie to*...\")\n"
     ]
    }
   ],
   "source": [
    "query = \"What are some good movies to watch on a rainy day?\"\n",
    "\n",
    "answer = advanced_rag_pipeline(query)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c849db5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advanced_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
